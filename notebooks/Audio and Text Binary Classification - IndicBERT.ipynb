{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Audio and Text Binary Classification - IndicBERT.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cn_DakbFAzowx3Ro4W19KJ5gAAyVaRke","authorship_tag":"ABX9TyNN6+Q2ga7k+E+2xKQjo7df"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"gxesfL1skK4h"},"source":["!pip install transformers -q\n","!pip install sentencepiece -q\n","!pip install -q -U tensorflow-text\n","!pip install -q tf-models-official"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VlZ0-OZZkPU"},"source":["import os\n","import shutil\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization\n","\n","import numpy as np\n","import pandas as pd\n","\n","from transformers import AutoModel, AutoTokenizer \n","from transformers import AdamW\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn as nn\n","device = torch.device(\"cuda\")\n","cpu = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpB-LjIdvoFg"},"source":["data = pd.read_json('/content/drive/MyDrive/mp3_data_w_vectors.json')\n","data['iGenre'] = data.apply(lambda x:int(x.Genre=='Romantic'),axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQB4oKkaaqWt","executionInfo":{"status":"ok","timestamp":1632643471389,"user_tz":-330,"elapsed":639,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"d0c435da-d857-43fd-e215-2e54966058c6"},"source":["indic_model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'sop_classifier.classifier.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"YmSGgVXklmJc"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QeGapwIU_NVE"},"source":["txt = list(data.apply(lambda x:x.Lyric,axis=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IO9_dYO5-9eO"},"source":["sent_id = tokenizer.batch_encode_plus(txt, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKTO2aKd14On"},"source":["max_seq_len = 25\n","all_tokens = tokenizer.batch_encode_plus(txt, max_length=max_seq_len,padding='longest', truncation=True, return_token_type_ids=False)\n","all_seq = torch.tensor(all_tokens['input_ids'])\n","all_mask = torch.tensor(all_tokens['attention_mask'])\n","all_y = torch.tensor(data['iGenre'].tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wa1UGyg53sJ_"},"source":["def get_data_loader(seq,mask,y,batch_size = 32):\n","  data = TensorDataset(seq, mask, y)\n","  sampler = RandomSampler(data)\n","  dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","  return (data,sampler,dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-2ZRtBFALmY"},"source":["max_seq_len = 75"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLbr-4KZBoUI"},"source":["def get_data_loader(seq,mask,y,batch_size = 16):\n","  data = TensorDataset(seq, mask, y)\n","  sampler = RandomSampler(data)\n","  dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","  return (data,sampler,dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrKqt8ZeDKB2"},"source":["for param in indic_model.parameters():\n","    param.requires_grad = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AN7zC1dHDQ6k"},"source":["class BERT_Arch(nn.Module):\n","    def __init__(self, bert):      \n","      super(BERT_Arch, self).__init__()\n","      self.bert = bert\n","      self.dropout = nn.Dropout(0.1)\n","      self.relu =  nn.ReLU()\n","      self.fc1 = nn.Linear(768,512)      \n","      self.fc2 = nn.Linear(512,2)\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sent_id, mask):\n","      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n","      x = self.fc1(cls_hs)\n","      x = self.relu(x)\n","      x = self.dropout(x)\n","      x = self.fc2(x)\n","      x = self.softmax(x)\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwSiH86W5Epm"},"source":["def train(model,train_dataloader,loss_fcn):\n","  model.train()\n","  total_loss, total_accuracy = 0, 0\n","  # empty list to save model predictions\n","  total_preds=[]  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):    \n","    if step % 20 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n","    sent_id, mask, labels = batch\n","    # clear previously calculated gradients \n","    model.zero_grad()\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","    # compute the loss between actual and predicted values\n","    loss = loss_fcn(preds, labels)\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    # update parameters\n","    optimizer.step()\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","    # append the model predictions\n","    total_preds.append(preds)\n","    del batch\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rgWv4nE75G8O"},"source":["def evaluate(model,val_dataloader,loss_fcn):\n","  print(\"\\nEvaluating...\")\n","  # deactivate dropout layers\n","  model.eval()\n","  total_loss, total_accuracy = 0, 0  \n","  # empty list to save the model predictions\n","  total_preds = []\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):    \n","    if step % 20 == 0 and not step == 0:      \n","      # Calculate elapsed time in minutes.\n","      elapsed = format_time(time.time() - t0)            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","    sent_id, mask, labels = batch\n","    preds = model(sent_id, mask)\n","    # compute the validation loss between actual and predicted values\n","    loss = loss_fcn(preds,labels)\n","    total_loss = total_loss + loss.item()\n","    preds = preds.detach().cpu().numpy()\n","    total_preds.append(preds)\n","    del batch\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtOqcNX64PQO","executionInfo":{"status":"ok","timestamp":1632643792334,"user_tz":-330,"elapsed":316337,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"695722e6-11d6-4367-bb93-befe3d9f0bc0"},"source":["k_folds = 5\n","# number of training epochs\n","epochs = 5\n","torch.manual_seed(42)\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","models = [BERT_Arch(indic_model) for x in range(k_folds)]\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(data)):\n","  print(f'FOLD {fold}')\n","  print('--------------------------------')\n","  train_data, train_sampler, train_dataloader = get_data_loader(all_seq[train_ids],all_mask[train_ids],all_y[train_ids])\n","  test_data, test_sampler, test_dataloader = get_data_loader(all_seq[test_ids],all_mask[test_ids],all_y[test_ids])\n","  best_valid_loss = float('inf')\n","  models[fold].to(device)\n","  class_wts = compute_class_weight('balanced', np.unique(all_y[train_ids].tolist()), all_y[train_ids].tolist())\n","  print(class_wts)\n","  # convert class weights to tensor\n","  weights= torch.tensor(class_wts,dtype=torch.float)\n","  weights = weights.to(device)\n","  # loss function\n","  loss_fcn  = nn.NLLLoss(weight=weights)\n","  # empty lists to store training and validation loss of each epoch\n","  train_losses=[]\n","  valid_losses=[]\n","  # define the optimizer\n","  optimizer = AdamW(models[fold].parameters(), lr = 1e-5)\n","  #for each epoch\n","  for epoch in range(epochs):     \n","      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","      #train model\n","      train_loss, _ = train(models[fold],train_dataloader,loss_fcn)    \n","      #evaluate model\n","      valid_loss, _ = evaluate(models[fold],test_dataloader,loss_fcn)    \n","      #save the best model\n","      if valid_loss < best_valid_loss:\n","          best_valid_loss = valid_loss\n","          torch.save(models[fold].state_dict(), 'saved_weights.pt')      \n","      # append training and validation loss\n","      train_losses.append(train_loss)\n","      valid_losses.append(valid_loss)    \n","      print(f'\\nTraining Loss: {train_loss:.3f}')\n","      print(f'Validation Loss: {valid_loss:.3f}')\n","      torch.cuda.empty_cache()\n","  models[fold].load_state_dict(torch.load('saved_weights.pt'))\n","  preds = models[fold](all_seq[test_ids].to(device), all_mask[test_ids].to(device))\n","  preds = preds.detach().cpu().numpy()\n","  preds = np.argmax(preds, axis = 1)\n","  print('Test')\n","  print(classification_report(all_y[test_ids], preds))\n","  print(pd.crosstab(all_y[test_ids], preds))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","[0.74701874 1.51206897]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.694\n","Validation Loss: 0.692\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.692\n","Validation Loss: 0.690\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.677\n","Validation Loss: 0.676\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.642\n","Validation Loss: 0.666\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.609\n","Validation Loss: 0.664\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.44      0.57       140\n","           1       0.45      0.80      0.58        80\n","\n","    accuracy                           0.57       220\n","   macro avg       0.62      0.62      0.57       220\n","weighted avg       0.67      0.57      0.57       220\n","\n","col_0   0   1\n","row_0        \n","0      62  78\n","1      16  64\n","FOLD 1\n","--------------------------------\n","[0.75214408 1.4914966 ]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.637\n","Validation Loss: 0.712\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.650\n","Validation Loss: 0.595\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.580\n","Validation Loss: 0.620\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.569\n","Validation Loss: 0.628\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.529\n","Validation Loss: 0.674\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.77      0.82       144\n","           1       0.65      0.79      0.71        76\n","\n","    accuracy                           0.78       220\n","   macro avg       0.76      0.78      0.76       220\n","weighted avg       0.79      0.78      0.78       220\n","\n","col_0    0   1\n","row_0         \n","0      111  33\n","1       16  60\n","FOLD 2\n","--------------------------------\n","[0.76480836 1.44407895]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.653\n","Validation Loss: 0.569\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.605\n","Validation Loss: 0.551\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.578\n","Validation Loss: 0.516\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.516\n","Validation Loss: 0.617\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.511\n","Validation Loss: 0.498\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.89      0.89       153\n","           1       0.74      0.73      0.73        66\n","\n","    accuracy                           0.84       219\n","   macro avg       0.81      0.81      0.81       219\n","weighted avg       0.84      0.84      0.84       219\n","\n","col_0    0   1\n","row_0         \n","0      136  17\n","1       18  48\n","FOLD 3\n","--------------------------------\n","[0.75042735 1.49829352]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.580\n","Validation Loss: 0.519\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.496\n","Validation Loss: 0.462\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.442\n","Validation Loss: 0.432\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.408\n","Validation Loss: 0.482\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.342\n","Validation Loss: 0.371\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.87      0.92       142\n","           1       0.80      0.95      0.87        77\n","\n","    accuracy                           0.90       219\n","   macro avg       0.89      0.91      0.89       219\n","weighted avg       0.91      0.90      0.90       219\n","\n","col_0    0   1\n","row_0         \n","0      124  18\n","1        4  73\n","FOLD 4\n","--------------------------------\n","[0.7582038  1.46822742]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.540\n","Validation Loss: 0.435\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.409\n","Validation Loss: 0.350\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.313\n","Validation Loss: 0.285\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.259\n","Validation Loss: 0.226\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.252\n","Validation Loss: 0.275\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.93      0.95       148\n","           1       0.86      0.97      0.91        71\n","\n","    accuracy                           0.94       219\n","   macro avg       0.92      0.95      0.93       219\n","weighted avg       0.95      0.94      0.94       219\n","\n","col_0    0   1\n","row_0         \n","0      137  11\n","1        2  69\n"]}]},{"cell_type":"code","metadata":{"id":"KiGKV5v3BzN9"},"source":[""],"execution_count":null,"outputs":[]}]}