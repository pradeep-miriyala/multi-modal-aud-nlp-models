{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Audio_and_Text_Binary_Classification_XLMR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8837d986f22a473baf8302e0ac6ae4af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_442146cf70f84affb1f5c25c74a29467","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52ef4ac01d4e4ee2857250167070dc53","IPY_MODEL_ed1975120070499cb89c52d5ec77eab3","IPY_MODEL_2162aec4b5a3432e93964054d0a5838c"]}},"442146cf70f84affb1f5c25c74a29467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52ef4ac01d4e4ee2857250167070dc53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd89e2837c084268ab568d95831fb675","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2c521884792439ba8cf20145423a1ab"}},"ed1975120070499cb89c52d5ec77eab3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80d1d8ee3ad54bb6806431bc455f5eab","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dc25798de3a489e80ed3f6e3e4ad85b"}},"2162aec4b5a3432e93964054d0a5838c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d828aae829f9481bb19f723518c7bd95","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 11.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33f1a4c2282944269e8d0cda6717b96e"}},"bd89e2837c084268ab568d95831fb675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2c521884792439ba8cf20145423a1ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80d1d8ee3ad54bb6806431bc455f5eab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6dc25798de3a489e80ed3f6e3e4ad85b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d828aae829f9481bb19f723518c7bd95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33f1a4c2282944269e8d0cda6717b96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9bcf69ac91b4f67b8bfdca64e6829fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9e3dc02ba27c435baf4c022df18e889c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1080303f4f8149508bb5f38737fb6ae9","IPY_MODEL_51a608b3516241b1a1839b2ed13cea83","IPY_MODEL_fb211c13bb804c2f9535d827daff9940"]}},"9e3dc02ba27c435baf4c022df18e889c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1080303f4f8149508bb5f38737fb6ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2af063397799461899ff492d4cb10806","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e911fcdb28f042238a146b9b113beca7"}},"51a608b3516241b1a1839b2ed13cea83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_875f726c039f4dd9a8eca566fc9c8628","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_144db1bef6054345b8d531f0ca30c070"}},"fb211c13bb804c2f9535d827daff9940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7c742e2a17e94741bdb4ec9fc0232b18","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.12G/1.12G [00:34&lt;00:00, 33.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aaaaad402f9a4a1680220f6f4338ea3a"}},"2af063397799461899ff492d4cb10806":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e911fcdb28f042238a146b9b113beca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"875f726c039f4dd9a8eca566fc9c8628":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"144db1bef6054345b8d531f0ca30c070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c742e2a17e94741bdb4ec9fc0232b18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aaaaad402f9a4a1680220f6f4338ea3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00233b364b1c4c66a48a43a59a492662":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2b0bffcf25934b1ea9bb9d85d6474eb8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1e20ca51a9444b38f873b4fd793d467","IPY_MODEL_fa2b628c671c4f1aa16f71e4b6e1d104","IPY_MODEL_2cacea41806e4f3e8a97e4446d05798e"]}},"2b0bffcf25934b1ea9bb9d85d6474eb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1e20ca51a9444b38f873b4fd793d467":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7575903644b4424b80de8e0d5d01d897","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a48cf795c245475e85bba4efdd88b850"}},"fa2b628c671c4f1aa16f71e4b6e1d104":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2bd28280c5c64fafa5c8bb6b1ba54564","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a28668428184f62b498e3380144d910"}},"2cacea41806e4f3e8a97e4446d05798e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdcd912d1b574d4a9093140188c5e30e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:00&lt;00:00, 9.87MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ef6b804235349f8928126a72d618c8f"}},"7575903644b4424b80de8e0d5d01d897":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a48cf795c245475e85bba4efdd88b850":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bd28280c5c64fafa5c8bb6b1ba54564":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a28668428184f62b498e3380144d910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cdcd912d1b574d4a9093140188c5e30e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ef6b804235349f8928126a72d618c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa8ebc99a0794b06b4d53ee8e2b22f66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_16c6cdf3a75948acb8e6cb0d65136ab7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b511f7ec41b47de80222c984f6a2c8e","IPY_MODEL_1aeb08ae604f479eaeaf7273facdc26d","IPY_MODEL_2b08495ad1e04aa3a9a2993f1eb11621"]}},"16c6cdf3a75948acb8e6cb0d65136ab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b511f7ec41b47de80222c984f6a2c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_90f1e3d593134f7fa340749f7e1e3084","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14ca51888c13494592a7ea274676c481"}},"1aeb08ae604f479eaeaf7273facdc26d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_740a30ad93c34c42a4d31cae6999b3bd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9096718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9096718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee471724fb64498d91331d90b78327f8"}},"2b08495ad1e04aa3a9a2993f1eb11621":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_73174a7484e043748a69096e7eef95d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9.10M/9.10M [00:00&lt;00:00, 23.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffb95b3e3cd04e9287ca4b5344c75f71"}},"90f1e3d593134f7fa340749f7e1e3084":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"14ca51888c13494592a7ea274676c481":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"740a30ad93c34c42a4d31cae6999b3bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee471724fb64498d91331d90b78327f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73174a7484e043748a69096e7eef95d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ffb95b3e3cd04e9287ca4b5344c75f71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gxesfL1skK4h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632723535256,"user_tz":-330,"elapsed":32759,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"3ce47585-e7f3-435d-9ab5-dc6fdd41a9e3"},"source":["!pip install transformers -q\n","!pip install sentencepiece -q\n","!pip install -q -U tensorflow-text\n","!pip install -q tf-models-official"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 35.3 MB/s \n","\u001b[K     |████████████████████████████████| 636 kB 46.0 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 47.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 4.4 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 49.2 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 211 kB 49.4 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 9.0 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 30.3 MB/s \n","\u001b[K     |████████████████████████████████| 37.1 MB 48 kB/s \n","\u001b[K     |████████████████████████████████| 90 kB 9.0 MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"1VlZ0-OZZkPU","executionInfo":{"status":"ok","timestamp":1632723542225,"user_tz":-330,"elapsed":6987,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["import os\n","import shutil\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization\n","\n","import numpy as np\n","import pandas as pd\n","\n","from transformers import AutoModel, AutoTokenizer \n","from transformers import AdamW\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn as nn\n","device = torch.device(\"cuda\")\n","cpu = torch.device(\"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uUt9B9t5TvG","executionInfo":{"status":"ok","timestamp":1632723565893,"user_tz":-330,"elapsed":23690,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"addcc7f2-eead-44c2-f0d8-31efa129ffcf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"dpB-LjIdvoFg","executionInfo":{"status":"ok","timestamp":1632723566335,"user_tz":-330,"elapsed":445,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["data = pd.read_json('/content/drive/MyDrive/mp3_data_w_vectors.json')\n","data['iGenre'] = data.apply(lambda x:int(x.Genre=='Devotional'),axis=1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152,"referenced_widgets":["8837d986f22a473baf8302e0ac6ae4af","442146cf70f84affb1f5c25c74a29467","52ef4ac01d4e4ee2857250167070dc53","ed1975120070499cb89c52d5ec77eab3","2162aec4b5a3432e93964054d0a5838c","bd89e2837c084268ab568d95831fb675","f2c521884792439ba8cf20145423a1ab","80d1d8ee3ad54bb6806431bc455f5eab","6dc25798de3a489e80ed3f6e3e4ad85b","d828aae829f9481bb19f723518c7bd95","33f1a4c2282944269e8d0cda6717b96e","b9bcf69ac91b4f67b8bfdca64e6829fa","9e3dc02ba27c435baf4c022df18e889c","1080303f4f8149508bb5f38737fb6ae9","51a608b3516241b1a1839b2ed13cea83","fb211c13bb804c2f9535d827daff9940","2af063397799461899ff492d4cb10806","e911fcdb28f042238a146b9b113beca7","875f726c039f4dd9a8eca566fc9c8628","144db1bef6054345b8d531f0ca30c070","7c742e2a17e94741bdb4ec9fc0232b18","aaaaad402f9a4a1680220f6f4338ea3a"]},"id":"hQB4oKkaaqWt","executionInfo":{"status":"ok","timestamp":1632723605134,"user_tz":-330,"elapsed":38801,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"fd24c552-7fe0-4dce-9897-750be5e4a06b"},"source":["indic_model = AutoModel.from_pretrained(\"xlm-roberta-base\")"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8837d986f22a473baf8302e0ac6ae4af","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9bcf69ac91b4f67b8bfdca64e6829fa","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"YmSGgVXklmJc","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["00233b364b1c4c66a48a43a59a492662","2b0bffcf25934b1ea9bb9d85d6474eb8","f1e20ca51a9444b38f873b4fd793d467","fa2b628c671c4f1aa16f71e4b6e1d104","2cacea41806e4f3e8a97e4446d05798e","7575903644b4424b80de8e0d5d01d897","a48cf795c245475e85bba4efdd88b850","2bd28280c5c64fafa5c8bb6b1ba54564","3a28668428184f62b498e3380144d910","cdcd912d1b574d4a9093140188c5e30e","4ef6b804235349f8928126a72d618c8f","fa8ebc99a0794b06b4d53ee8e2b22f66","16c6cdf3a75948acb8e6cb0d65136ab7","9b511f7ec41b47de80222c984f6a2c8e","1aeb08ae604f479eaeaf7273facdc26d","2b08495ad1e04aa3a9a2993f1eb11621","90f1e3d593134f7fa340749f7e1e3084","14ca51888c13494592a7ea274676c481","740a30ad93c34c42a4d31cae6999b3bd","ee471724fb64498d91331d90b78327f8","73174a7484e043748a69096e7eef95d2","ffb95b3e3cd04e9287ca4b5344c75f71"]},"executionInfo":{"status":"ok","timestamp":1632723607757,"user_tz":-330,"elapsed":2639,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"fd6f489e-c1d1-4877-b0ad-6ea3c0f1b0f5"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00233b364b1c4c66a48a43a59a492662","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa8ebc99a0794b06b4d53ee8e2b22f66","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"QeGapwIU_NVE","executionInfo":{"status":"ok","timestamp":1632723607757,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["txt = list(data.apply(lambda x:x.Lyric,axis=1))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IO9_dYO5-9eO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632723608729,"user_tz":-330,"elapsed":975,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"ddc66fb1-63c5-4632-aa51-b129fd73f3f7"},"source":["sent_id = tokenizer.batch_encode_plus(txt, padding=True, return_token_type_ids=False)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","metadata":{"id":"HKTO2aKd14On","executionInfo":{"status":"ok","timestamp":1632723609213,"user_tz":-330,"elapsed":486,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["max_seq_len = 25\n","all_tokens = tokenizer.batch_encode_plus(txt, max_length=max_seq_len,padding='longest', truncation=True, return_token_type_ids=False)\n","all_seq = torch.tensor(all_tokens['input_ids'])\n","all_mask = torch.tensor(all_tokens['attention_mask'])\n","all_y = torch.tensor(data['iGenre'].tolist())"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wa1UGyg53sJ_","executionInfo":{"status":"ok","timestamp":1632723609213,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["def get_data_loader(seq,mask,y,batch_size = 32):\n","  data = TensorDataset(seq, mask, y)\n","  sampler = RandomSampler(data)\n","  dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","  return (data,sampler,dataloader)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-2ZRtBFALmY","executionInfo":{"status":"ok","timestamp":1632723609213,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["max_seq_len = 75"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLbr-4KZBoUI","executionInfo":{"status":"ok","timestamp":1632723609214,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["def get_data_loader(seq,mask,y,batch_size = 16):\n","  data = TensorDataset(seq, mask, y)\n","  sampler = RandomSampler(data)\n","  dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","  return (data,sampler,dataloader)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrKqt8ZeDKB2","executionInfo":{"status":"ok","timestamp":1632723609214,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["for param in indic_model.parameters():\n","    param.requires_grad = True"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AN7zC1dHDQ6k","executionInfo":{"status":"ok","timestamp":1632723609214,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["class BERT_Arch(nn.Module):\n","    def __init__(self, bert):      \n","      super(BERT_Arch, self).__init__()\n","      self.bert = bert\n","      self.dropout = nn.Dropout(0.1)\n","      self.relu =  nn.ReLU()\n","      self.fc1 = nn.Linear(768,512)      \n","      self.fc2 = nn.Linear(512,2)\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sent_id, mask):\n","      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n","      x = self.fc1(cls_hs)\n","      x = self.relu(x)\n","      x = self.dropout(x)\n","      x = self.fc2(x)\n","      x = self.softmax(x)\n","      return x"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwSiH86W5Epm","executionInfo":{"status":"ok","timestamp":1632723609214,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["def train(model,train_dataloader,loss_fcn):\n","  model.train()\n","  total_loss, total_accuracy = 0, 0\n","  # empty list to save model predictions\n","  total_preds=[]  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):    \n","    if step % 20 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n","    sent_id, mask, labels = batch\n","    # clear previously calculated gradients \n","    model.zero_grad()\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","    # compute the loss between actual and predicted values\n","    loss = loss_fcn(preds, labels)\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    # update parameters\n","    optimizer.step()\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","    # append the model predictions\n","    total_preds.append(preds)\n","    del batch\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rgWv4nE75G8O","executionInfo":{"status":"ok","timestamp":1632723609215,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":["def evaluate(model,val_dataloader,loss_fcn):\n","  print(\"\\nEvaluating...\")\n","  # deactivate dropout layers\n","  model.eval()\n","  total_loss, total_accuracy = 0, 0  \n","  # empty list to save the model predictions\n","  total_preds = []\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):    \n","    if step % 20 == 0 and not step == 0:      \n","      # Calculate elapsed time in minutes.\n","      elapsed = format_time(time.time() - t0)            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","    sent_id, mask, labels = batch\n","    preds = model(sent_id, mask)\n","    # compute the validation loss between actual and predicted values\n","    loss = loss_fcn(preds,labels)\n","    total_loss = total_loss + loss.item()\n","    preds = preds.detach().cpu().numpy()\n","    total_preds.append(preds)\n","    del batch\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","  return avg_loss, total_preds"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtOqcNX64PQO","executionInfo":{"status":"ok","timestamp":1632724203821,"user_tz":-330,"elapsed":594611,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}},"outputId":"b589c410-cd0e-4ba7-d95b-b045f0985b9e"},"source":["k_folds = 5\n","# number of training epochs\n","epochs = 5\n","torch.manual_seed(42)\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","models = [BERT_Arch(indic_model) for x in range(k_folds)]\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(data)):\n","  print(f'FOLD {fold}')\n","  print('--------------------------------')\n","  train_data, train_sampler, train_dataloader = get_data_loader(all_seq[train_ids],all_mask[train_ids],all_y[train_ids])\n","  test_data, test_sampler, test_dataloader = get_data_loader(all_seq[test_ids],all_mask[test_ids],all_y[test_ids])\n","  best_valid_loss = float('inf')\n","  models[fold].to(device)\n","  class_wts = compute_class_weight('balanced', np.unique(all_y[train_ids].tolist()), all_y[train_ids].tolist())\n","  print(class_wts)\n","  # convert class weights to tensor\n","  weights= torch.tensor(class_wts,dtype=torch.float)\n","  weights = weights.to(device)\n","  # loss function\n","  loss_fcn  = nn.NLLLoss(weight=weights)\n","  # empty lists to store training and validation loss of each epoch\n","  train_losses=[]\n","  valid_losses=[]\n","  # define the optimizer\n","  optimizer = AdamW(models[fold].parameters(), lr = 1e-5)\n","  #for each epoch\n","  for epoch in range(epochs):     \n","      print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","      #train model\n","      train_loss, _ = train(models[fold],train_dataloader,loss_fcn)    \n","      #evaluate model\n","      valid_loss, _ = evaluate(models[fold],test_dataloader,loss_fcn)    \n","      #save the best model\n","      if valid_loss < best_valid_loss:\n","          best_valid_loss = valid_loss\n","          torch.save(models[fold].state_dict(), 'saved_weights.pt')      \n","      # append training and validation loss\n","      train_losses.append(train_loss)\n","      valid_losses.append(valid_loss)    \n","      print(f'\\nTraining Loss: {train_loss:.3f}')\n","      print(f'Validation Loss: {valid_loss:.3f}')\n","      torch.cuda.empty_cache()\n","  models[fold].load_state_dict(torch.load('saved_weights.pt'))\n","  preds = models[fold](all_seq[test_ids].to(device), all_mask[test_ids].to(device))\n","  preds = preds.detach().cpu().numpy()\n","  preds = np.argmax(preds, axis = 1)\n","  print('Test')\n","  print(classification_report(all_y[test_ids], preds))\n","  print(pd.crosstab(all_y[test_ids], preds))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","[1.51730104 0.7457483 ]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.694\n","Validation Loss: 0.688\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.662\n","Validation Loss: 0.613\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.603\n","Validation Loss: 0.759\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.563\n","Validation Loss: 0.524\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.510\n","Validation Loss: 0.625\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.78      0.70        81\n","           1       0.85      0.75      0.80       139\n","\n","    accuracy                           0.76       220\n","   macro avg       0.75      0.76      0.75       220\n","weighted avg       0.78      0.76      0.76       220\n","\n","col_0   0    1\n","row_0         \n","0      63   18\n","1      35  104\n","FOLD 1\n","--------------------------------\n","[1.48141892 0.75473322]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.590\n","Validation Loss: 0.488\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.526\n","Validation Loss: 0.483\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.515\n","Validation Loss: 0.582\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.407\n","Validation Loss: 0.484\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.466\n","Validation Loss: 0.462\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.80      0.76        74\n","           1       0.89      0.84      0.87       146\n","\n","    accuracy                           0.83       220\n","   macro avg       0.81      0.82      0.81       220\n","weighted avg       0.83      0.83      0.83       220\n","\n","col_0   0    1\n","row_0         \n","0      59   15\n","1      23  123\n","FOLD 2\n","--------------------------------\n","[1.44407895 0.76480836]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.502\n","Validation Loss: 0.358\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.409\n","Validation Loss: 0.346\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.386\n","Validation Loss: 0.319\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.353\n","Validation Loss: 0.361\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.315\n","Validation Loss: 0.360\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.82      0.85        66\n","           1       0.92      0.95      0.94       153\n","\n","    accuracy                           0.91       219\n","   macro avg       0.90      0.89      0.89       219\n","weighted avg       0.91      0.91      0.91       219\n","\n","col_0   0    1\n","row_0         \n","0      54   12\n","1       7  146\n","FOLD 3\n","--------------------------------\n","[1.48310811 0.75429553]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.515\n","Validation Loss: 0.295\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.409\n","Validation Loss: 0.313\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.368\n","Validation Loss: 0.274\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.388\n","Validation Loss: 0.212\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.277\n","Validation Loss: 0.213\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.92      0.93        74\n","           1       0.96      0.97      0.96       145\n","\n","    accuracy                           0.95       219\n","   macro avg       0.95      0.94      0.94       219\n","weighted avg       0.95      0.95      0.95       219\n","\n","col_0   0    1\n","row_0         \n","0      68    6\n","1       5  140\n","FOLD 4\n","--------------------------------\n","[1.48813559 0.75300172]\n","\n"," Epoch 1 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.427\n","Validation Loss: 0.188\n","\n"," Epoch 2 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.287\n","Validation Loss: 0.130\n","\n"," Epoch 3 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.299\n","Validation Loss: 0.225\n","\n"," Epoch 4 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.287\n","Validation Loss: 0.227\n","\n"," Epoch 5 / 5\n","  Batch    20  of     55.\n","  Batch    40  of     55.\n","\n","Evaluating...\n","\n","Training Loss: 0.288\n","Validation Loss: 0.189\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96        75\n","           1       0.98      0.98      0.98       144\n","\n","    accuracy                           0.97       219\n","   macro avg       0.97      0.97      0.97       219\n","weighted avg       0.97      0.97      0.97       219\n","\n","col_0   0    1\n","row_0         \n","0      72    3\n","1       3  141\n"]}]},{"cell_type":"code","metadata":{"id":"KiGKV5v3BzN9","executionInfo":{"status":"ok","timestamp":1632724203822,"user_tz":-330,"elapsed":15,"user":{"displayName":"Pradeep Miriyala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01285334170127158064"}}},"source":[""],"execution_count":17,"outputs":[]}]}